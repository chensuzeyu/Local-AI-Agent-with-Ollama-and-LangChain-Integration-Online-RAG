# Local-AI-Agent-with-Ollama-and-LangChain-Integration-Online-RAG
This project demonstrates deploying the private local LLM Qwen2.5:1.5b with Ollama. It uses LangChain for intelligent agent dev on policy analysis.   Combining RAG and local memory, it processes sensitive data locally to address privacy, fitting government services, enterprise KM, and digital platforms. 
